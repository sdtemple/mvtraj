{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvtrajectories import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = pd.read_csv('mb-relative-abundances.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(30821)\n",
    "ktable = pd.DataFrame(columns = ['k', 'Rand', 'Dunn'], dtype = np.float64)\n",
    "ks = [4, 6, 8, 10]\n",
    "N = 10\n",
    "scalar = 0.001\n",
    "nrm = zero_inflated_lp_norm\n",
    "ids = list(mb['patientID'].unique())\n",
    "patients = mb.groupby(['patientID']).size()\n",
    "six = list(patients[patients >= 6].index) # somewhat large initial trajectories\n",
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "itr = 1\n",
    "for k in ks:\n",
    "    rs = []\n",
    "    ds = []\n",
    "    \n",
    "    # make a list of Trajectory class objects\n",
    "    trajectories = []\n",
    "    for i in range(len(ids)):\n",
    "        subset = mb[mb['patientID'] == ids[i]]\n",
    "        trajectories.append(Trajectory(ids[i], subset.iloc[:,5:].values, subset.iloc[:,1].values, scalar))\n",
    "    \n",
    "    # initialize clusters randomly\n",
    "    init_ids = random.sample(six, k) # initial clusters have cluster size 6\n",
    "    clusters = []\n",
    "    for i in init_ids:\n",
    "        idx = ids.index(i)\n",
    "        clusters.append(deepcopy(trajectories[idx]))\n",
    "    for i in range(k):\n",
    "        clusters[i].cluster = i # name clusters\n",
    "        \n",
    "    prev_assign = [0 for x in range(len(trajectories))]\n",
    "    curr_assign = [1 for x in range(len(trajectories))]\n",
    "    ctr = 0\n",
    "    while curr_assign != prev_assign:\n",
    "        ctr += 1\n",
    "        prev_assign = curr_assign\n",
    "        # assign to clusters\n",
    "        for i in range(len(ids)):\n",
    "            frsp = free_space(trajectories[i].longitudinal, \n",
    "                              clusters[0].longitudinal,\n",
    "                              trajectories[i].times,\n",
    "                              clusters[0].times,\n",
    "                              nrm)\n",
    "            idx = clusters[0].cluster\n",
    "            dist = frechet_dist(frsp)\n",
    "            traj = backtrack(frsp)\n",
    "            for j in range(1, k):\n",
    "                frsp = free_space(trajectories[i].longitudinal, \n",
    "                                  clusters[j].longitudinal,\n",
    "                                  trajectories[i].times,\n",
    "                                  clusters[j].times,\n",
    "                                  nrm)\n",
    "                curr = frechet_dist(frsp)\n",
    "                if curr < dist:\n",
    "                    dist = curr\n",
    "                    traj = backtrack(frsp)\n",
    "                    idx = clusters[j].cluster\n",
    "            trajectories[i].cluster = idx\n",
    "            trajectories[i].parameterization = traj\n",
    "            trajectories[i].dist = dist\n",
    "    \n",
    "        # calculate cluster trajectory\n",
    "        for i in range(k):\n",
    "            cl = [x for x in trajectories if x.cluster == clusters[i].cluster]\n",
    "            clusters[i].longitudinal, clusters[i].times = mean_trajectory(cl)\n",
    "        \n",
    "        curr_assign = [x.cluster for x in trajectories]\n",
    "        \n",
    "    prevassign = [x.cluster for x in trajectories]\n",
    "    ds.append(a_dunn_like_index(trajectories, clusters, nrm))\n",
    "    \n",
    "    for n in range(N):\n",
    "        print(k, n)\n",
    "        \n",
    "        # make a list of Trajectory class objects\n",
    "        trajectories = []\n",
    "        ids = list(mb['patientID'].unique())\n",
    "        for i in range(len(ids)):\n",
    "            subset = mb[mb['patientID'] == ids[i]]\n",
    "            trajectories.append(Trajectory(ids[i], subset.iloc[:,5:].values, subset.iloc[:,1].values, scalar))\n",
    "        \n",
    "        patients = mb.groupby(['patientID']).size()\n",
    "        six = list(patients[patients >= 6].index) # somewhat large initial trajectories\n",
    "    \n",
    "        # initialize clusters randomly\n",
    "        init_ids = random.sample(six, k) # initial clusters have cluster size 6\n",
    "        clusters = []\n",
    "        for i in init_ids:\n",
    "            idx = ids.index(i)\n",
    "            clusters.append(deepcopy(trajectories[idx]))\n",
    "        for i in range(k):\n",
    "            clusters[i].cluster = i # name clusters\n",
    "        \n",
    "        prev_assign = [0 for x in range(len(trajectories))]\n",
    "        curr_assign = [1 for x in range(len(trajectories))]\n",
    "        ctr = 0\n",
    "        while curr_assign != prev_assign:\n",
    "            ctr += 1\n",
    "            prev_assign = curr_assign\n",
    "            # assign to clusters\n",
    "            for i in range(len(ids)):\n",
    "                frsp = free_space(trajectories[i].longitudinal, \n",
    "                                  clusters[0].longitudinal,\n",
    "                                  trajectories[i].times,\n",
    "                                  clusters[0].times,\n",
    "                                  zero_inflated_lp_norm)\n",
    "                idx = clusters[0].cluster\n",
    "                dist = frechet_dist(frsp)\n",
    "                traj = backtrack(frsp)\n",
    "                for j in range(1, k):\n",
    "                    frsp = free_space(trajectories[i].longitudinal, \n",
    "                                      clusters[j].longitudinal,\n",
    "                                      trajectories[i].times,\n",
    "                                      clusters[j].times,\n",
    "                                      nrm)\n",
    "                    curr = frechet_dist(frsp)\n",
    "                    if curr < dist:\n",
    "                        dist = curr\n",
    "                        traj = backtrack(frsp)\n",
    "                        idx = clusters[j].cluster\n",
    "                trajectories[i].cluster = idx\n",
    "                trajectories[i].parameterization = traj\n",
    "                trajectories[i].dist = dist\n",
    "    \n",
    "            # calculate cluster trajectory\n",
    "            for i in range(k):\n",
    "                cl = [x for x in trajectories if x.cluster == clusters[i].cluster]\n",
    "                clusters[i].longitudinal, clusters[i].times = mean_trajectory(cl)\n",
    "        \n",
    "            curr_assign = [x.cluster for x in trajectories]\n",
    "            \n",
    "        ds.append(a_dunn_like_index(trajectories, clusters, nrm))\n",
    "        currassign = [x.cluster for x in trajectories]\n",
    "        rs.append(rand_index(prevassign, currassign))\n",
    "        prevassign = currassign\n",
    "        \n",
    "    ktable.loc[itr] = [k, mean(rs), mean(ds)]\n",
    "    itr += 1\n",
    "    \n",
    "ktable.to_csv('k-parameter-search.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(30921)\n",
    "stable = pd.DataFrame(columns = ['Scalar', 'Rand', 'Dunn'], dtype = np.float64)\n",
    "ss = [0.01, 0.001, 0.0001]\n",
    "N = 10\n",
    "k = 6\n",
    "nrm = lp_norm\n",
    "ids = list(mb['patientID'].unique())\n",
    "patients = mb.groupby(['patientID']).size()\n",
    "six = list(patients[patients >= 6].index) # somewhat large initial trajectories\n",
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "itr = 1\n",
    "for s in ss:\n",
    "    rs = []\n",
    "    ds = []\n",
    "    \n",
    "    # make a list of Trajectory class objects\n",
    "    trajectories = []\n",
    "    for i in range(len(ids)):\n",
    "        subset = mb[mb['patientID'] == ids[i]]\n",
    "        trajectories.append(Trajectory(ids[i], subset.iloc[:,5:].values, subset.iloc[:,1].values, s))\n",
    "    \n",
    "    # initialize clusters randomly\n",
    "    init_ids = random.sample(six, k) # initial clusters have cluster size 6\n",
    "    clusters = []\n",
    "    for i in init_ids:\n",
    "        idx = ids.index(i)\n",
    "        clusters.append(deepcopy(trajectories[idx]))\n",
    "    for i in range(k):\n",
    "        clusters[i].cluster = i # name clusters\n",
    "        \n",
    "    prev_assign = [0 for x in range(len(trajectories))]\n",
    "    curr_assign = [1 for x in range(len(trajectories))]\n",
    "    ctr = 0\n",
    "    while curr_assign != prev_assign:\n",
    "        ctr += 1\n",
    "        prev_assign = curr_assign\n",
    "        # assign to clusters\n",
    "        for i in range(len(ids)):\n",
    "            frsp = free_space(trajectories[i].longitudinal, \n",
    "                              clusters[0].longitudinal,\n",
    "                              trajectories[i].times,\n",
    "                              clusters[0].times,\n",
    "                              nrm)\n",
    "            idx = clusters[0].cluster\n",
    "            dist = frechet_dist(frsp)\n",
    "            traj = backtrack(frsp)\n",
    "            for j in range(1, k):\n",
    "                frsp = free_space(trajectories[i].longitudinal, \n",
    "                                  clusters[j].longitudinal,\n",
    "                                  trajectories[i].times,\n",
    "                                  clusters[j].times,\n",
    "                                  nrm)\n",
    "                curr = frechet_dist(frsp)\n",
    "                if curr < dist:\n",
    "                    dist = curr\n",
    "                    traj = backtrack(frsp)\n",
    "                    idx = clusters[j].cluster\n",
    "            trajectories[i].cluster = idx\n",
    "            trajectories[i].parameterization = traj\n",
    "            trajectories[i].dist = dist\n",
    "    \n",
    "        # calculate cluster trajectory\n",
    "        for i in range(k):\n",
    "            cl = [x for x in trajectories if x.cluster == clusters[i].cluster]\n",
    "            clusters[i].longitudinal, clusters[i].times = mean_trajectory(cl)\n",
    "        \n",
    "        curr_assign = [x.cluster for x in trajectories]\n",
    "        \n",
    "    prevassign = [x.cluster for x in trajectories]\n",
    "    ds.append(a_dunn_like_index(trajectories, clusters, nrm))\n",
    "    \n",
    "    for n in range(N):\n",
    "        print(s, n)\n",
    "        \n",
    "        # make a list of Trajectory class objects\n",
    "        trajectories = []\n",
    "        ids = list(mb['patientID'].unique())\n",
    "        for i in range(len(ids)):\n",
    "            subset = mb[mb['patientID'] == ids[i]]\n",
    "            trajectories.append(Trajectory(ids[i], subset.iloc[:,5:].values, subset.iloc[:,1].values, s))\n",
    "        \n",
    "        patients = mb.groupby(['patientID']).size()\n",
    "        six = list(patients[patients >= 6].index) # somewhat large initial trajectories\n",
    "    \n",
    "        # initialize clusters randomly\n",
    "        init_ids = random.sample(six, k) # initial clusters have cluster size 6\n",
    "        clusters = []\n",
    "        for i in init_ids:\n",
    "            idx = ids.index(i)\n",
    "            clusters.append(deepcopy(trajectories[idx]))\n",
    "        for i in range(k):\n",
    "            clusters[i].cluster = i # name clusters\n",
    "        \n",
    "        prev_assign = [0 for x in range(len(trajectories))]\n",
    "        curr_assign = [1 for x in range(len(trajectories))]\n",
    "        ctr = 0\n",
    "        while curr_assign != prev_assign:\n",
    "            ctr += 1\n",
    "            prev_assign = curr_assign\n",
    "            # assign to clusters\n",
    "            for i in range(len(ids)):\n",
    "                frsp = free_space(trajectories[i].longitudinal, \n",
    "                                  clusters[0].longitudinal,\n",
    "                                  trajectories[i].times,\n",
    "                                  clusters[0].times,\n",
    "                                  zero_inflated_lp_norm)\n",
    "                idx = clusters[0].cluster\n",
    "                dist = frechet_dist(frsp)\n",
    "                traj = backtrack(frsp)\n",
    "                for j in range(1, k):\n",
    "                    frsp = free_space(trajectories[i].longitudinal, \n",
    "                                      clusters[j].longitudinal,\n",
    "                                      trajectories[i].times,\n",
    "                                      clusters[j].times,\n",
    "                                      nrm)\n",
    "                    curr = frechet_dist(frsp)\n",
    "                    if curr < dist:\n",
    "                        dist = curr\n",
    "                        traj = backtrack(frsp)\n",
    "                        idx = clusters[j].cluster\n",
    "                trajectories[i].cluster = idx\n",
    "                trajectories[i].parameterization = traj\n",
    "                trajectories[i].dist = dist\n",
    "    \n",
    "            # calculate cluster trajectory\n",
    "            for i in range(k):\n",
    "                cl = [x for x in trajectories if x.cluster == clusters[i].cluster]\n",
    "                clusters[i].longitudinal, clusters[i].times = mean_trajectory(cl)\n",
    "        \n",
    "            curr_assign = [x.cluster for x in trajectories]\n",
    "            \n",
    "        ds.append(a_dunn_like_index(trajectories, clusters, nrm))\n",
    "        currassign = [x.cluster for x in trajectories]\n",
    "        rs.append(rand_index(prevassign, currassign))\n",
    "        prevassign = currassign\n",
    "        \n",
    "    stable.loc[itr] = [s, mean(rs), mean(ds)]\n",
    "    itr += 1\n",
    "    \n",
    "stable.to_csv('scalar-parameter-search.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of Trajectory class objects\n",
    "trajectories = []\n",
    "scalar = 0.001\n",
    "nrm = zero_inflated_lp_norm\n",
    "ids = list(mb['patientID'].unique())\n",
    "for i in range(len(ids)):\n",
    "    subset = mb[mb['patientID'] == ids[i]]\n",
    "    trajectories.append(Trajectory(ids[i], subset.iloc[:,5:].values, subset.iloc[:,1].values, scalar))\n",
    "    \n",
    "patients = mb.groupby(['patientID']).size()\n",
    "six = list(patients[patients >= 6].index) # somewhat large initial trajectories\n",
    "\n",
    "# initialize clusters randomly\n",
    "random.seed(31021)\n",
    "k = 6\n",
    "#init_ids = random.sample(range(len(ids)), k)\n",
    "init_ids = random.sample(six, k) # initial clusters have cluster size 6\n",
    "clusters = []\n",
    "for i in init_ids:\n",
    "    idx = ids.index(i)\n",
    "    clusters.append(deepcopy(trajectories[idx]))\n",
    "for i in range(k):\n",
    "    clusters[i].cluster = i # name clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_assign = [0 for x in range(len(trajectories))]\n",
    "curr_assign = [1 for x in range(len(trajectories))]\n",
    "ctr = 0\n",
    "while curr_assign != prev_assign:\n",
    "    ctr = ctr + 1\n",
    "    prev_assign = curr_assign\n",
    "    # assign to clusters\n",
    "    for i in range(len(ids)):\n",
    "        frsp = free_space(trajectories[i].longitudinal, \n",
    "                          clusters[0].longitudinal,\n",
    "                          trajectories[i].times,\n",
    "                          clusters[0].times,\n",
    "                          nrm)\n",
    "        idx = clusters[0].cluster\n",
    "        dist = frechet_dist(frsp)\n",
    "        traj = backtrack(frsp)\n",
    "        for j in range(1, k):\n",
    "            frsp = free_space(trajectories[i].longitudinal, \n",
    "                              clusters[j].longitudinal,\n",
    "                              trajectories[i].times,\n",
    "                              clusters[j].times,\n",
    "                              nrm)\n",
    "            curr = frechet_dist(frsp)\n",
    "            if curr < dist:\n",
    "                dist = curr\n",
    "                traj = backtrack(frsp)\n",
    "                idx = clusters[j].cluster\n",
    "        trajectories[i].cluster = idx\n",
    "        trajectories[i].parameterization = traj\n",
    "        trajectories[i].dist = dist\n",
    "    \n",
    "    print('iteration', ctr)\n",
    "    for i in range(k):\n",
    "        print(len([x.identity for x in trajectories if x.cluster == i]))\n",
    "    \n",
    "    # calculate cluster trajectory\n",
    "    for i in range(k):\n",
    "        cl = [x for x in trajectories if x.cluster == clusters[i].cluster]\n",
    "        clusters[i].longitudinal, clusters[i].times = mean_trajectory(cl)\n",
    "        \n",
    "    curr_assign = [x.cluster for x in trajectories] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(mb.columns[5:]))\n",
    "multiline(clusters[0], scalar, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiline_save('results\\6-0.001\\cluster1.png', 'Cluster 1', clusters[0], scalar, False, xa = True, ya = True)\n",
    "for i in range(1, k):\n",
    "    multiline_save('results\\6-0.001\\cluster' + str(i+1) + '.png', 'Cluster ' + str(i+1), clusters[i], scalar, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some cluster exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "# how close are trajectories within clusters to the cluster mean\n",
    "for i in range(len(clusters)):\n",
    "    print('cluster', i + 1)\n",
    "    print('mean distance:', mean([x.dist for x in trajectories if x.cluster == i]))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how close are cluster mean trajectories\n",
    "for i in range(len(clusters)):\n",
    "    for j in range(i + 1, len(clusters)):\n",
    "        print(i + 1, '\\t', j + 1, '\\t', frechet_dist(free_space(clusters[i].longitudinal, \n",
    "                                            clusters[j].longitudinal,\n",
    "                                            clusters[i].times,\n",
    "                                            clusters[j].times,\n",
    "                                            zero_inflated_lp_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some output exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvhd = pd.read_csv('GvHD_Covariates_571.csv')\n",
    "gvhd['agvhgrd'] = gvhd['agvhgrd'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clusters)):\n",
    "    c = [x.identity for x in trajectories if x.cluster == i]\n",
    "    print('cluster', i + 1)\n",
    "    print('mean grade:', gvhd[gvhd['sub_ID'].isin(c)]['agvhgrd'].mean(skipna = True))\n",
    "    print('grades:', list(gvhd[gvhd['sub_ID'].isin(c)]['agvhgrd']))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [x.identity for x in trajectories if x.cluster == 0]\n",
    "ci = []\n",
    "for j in range(len(c)):\n",
    "    ci.append(ids.index(c[j]))\n",
    "out = mb[mb['patientID'].isin((mb['patientID'].unique())[ci])]\n",
    "out['cluster'] = 1\n",
    "\n",
    "for i in range(1, len(clusters)):\n",
    "    c = [x.identity for x in trajectories if x.cluster == i]\n",
    "    ci = []\n",
    "    for j in range(len(c)):\n",
    "        ci.append(ids.index(c[j]))\n",
    "    incoming = mb[mb['patientID'].isin((mb['patientID'].unique())[ci])]\n",
    "    incoming['cluster'] = (i + 1)\n",
    "    out = pd.concat([out, incoming])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv('results\\6-0.001\\final-mb-clusters-6-0.001.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
